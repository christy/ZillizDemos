{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "369c3444",
   "metadata": {},
   "source": [
    "# Embed Text Data & Load Vectors into Milvus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ffd11a",
   "metadata": {},
   "source": [
    "First, import some common libraries and define the data reading functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d7570b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import common libraries.\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Output words instead of scores.\n",
    "def sentiment_score_to_name(score: float):\n",
    "    if score > 0:\n",
    "        return \"Positive\"\n",
    "    elif score <= 0:\n",
    "        return \"Negative\"\n",
    "\n",
    "# Split data into train, valid, test. \n",
    "def partition_dataset(df_input, smoke_test=False):\n",
    "    \"\"\"Splits data, assuming original, input dataframe contains 50K rows.\n",
    "\n",
    "    Args:\n",
    "        df_input (pandas.DataFrame): input data frame\n",
    "        smoke_test (boolean): if True, use smaller number of rows for testing\n",
    "    \n",
    "    Returns:\n",
    "        df_train, df_val, df_test (pandas.DataFrame): train, valid, test splits.\n",
    "    \"\"\"\n",
    "\n",
    "    # Shuffle data and split into train/val/test.\n",
    "    df_shuffled = df_input.sample(frac=1, random_state=1).reset_index()\n",
    "    # Add a corpus index.\n",
    "    columns = ['movie_index', 'text', 'label_int', 'label']\n",
    "    df_shuffled.columns = columns\n",
    "\n",
    "    df_train = df_shuffled.iloc[:35_000]\n",
    "    df_val = df_shuffled.iloc[35_000:40_000]\n",
    "    df_test = df_shuffled.iloc[40_000:]\n",
    "\n",
    "    # Save train/val/test split data locally in separate files.\n",
    "    df_train.to_csv(\"train.csv\", index=False, encoding=\"utf-8\")\n",
    "    df_val.to_csv(\"val.csv\", index=False, encoding=\"utf-8\")\n",
    "    df_test.to_csv(\"test.csv\", index=False, encoding=\"utf-8\")\n",
    "\n",
    "    return df_shuffled, df_train, df_val, df_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a67e382",
   "metadata": {},
   "source": [
    "## Start up a local Milvus server."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb844837",
   "metadata": {},
   "source": [
    "Code in this notebook uses [Milvus lite](https://milvus.io/docs/milvus_lite.md), which runs a local server.  â›”ï¸ Milvus lite is only meant for demos and local testing.\n",
    "- pip install milvus pymilvus\n",
    "\n",
    "ðŸ’¡ **For production purposes**, use a local Milvus docker, Milvus clusters, or fully-managed Milvus on Zilliz Cloud.\n",
    "- [Local Milvus docker](https://milvus.io/docs/install_standalone-docker.md) requires local docker installed and running.\n",
    "- [Milvus clusters](https://milvus.io/docs/install_cluster-milvusoperator.md) requires a K8s cluster up and running.\n",
    "- [Ziliz Cloud free trial](https://cloud.zilliz.com/login) choose a \"free\" option when you provision.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69acd0f4",
   "metadata": {},
   "outputs": [
    {
     "ename": "TimeoutError",
     "evalue": "Milvus not startd in 180.0 seconds",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTimeoutError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/Users/christybergman/Documents/christy_github/ZillizDemos/milvus_onboarding/hello_world_milvus.ipynb Cell 6\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/christybergman/Documents/christy_github/ZillizDemos/milvus_onboarding/hello_world_milvus.ipynb#W5sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39m# Start a new milvus-lite local server.\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/christybergman/Documents/christy_github/ZillizDemos/milvus_onboarding/hello_world_milvus.ipynb#W5sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m start_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/christybergman/Documents/christy_github/ZillizDemos/milvus_onboarding/hello_world_milvus.ipynb#W5sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m default_server\u001b[39m.\u001b[39;49mstart()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/christybergman/Documents/christy_github/ZillizDemos/milvus_onboarding/hello_world_milvus.ipynb#W5sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m end_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/christybergman/Documents/christy_github/ZillizDemos/milvus_onboarding/hello_world_milvus.ipynb#W5sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mstartup time: \u001b[39m\u001b[39m{\u001b[39;00mend_time\u001b[39m \u001b[39m\u001b[39m-\u001b[39m\u001b[39m \u001b[39mstart_time\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/mambaforge/envs/py310/lib/python3.10/site-packages/milvus/__init__.py:432\u001b[0m, in \u001b[0;36mMilvusServer.start\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    430\u001b[0m os\u001b[39m.\u001b[39mchdir(old_pwd)\n\u001b[1;32m    431\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwait_for_started:\n\u001b[0;32m--> 432\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mwait_started()\n\u001b[1;32m    433\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_debug:\n\u001b[1;32m    434\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mshow_banner()\n",
      "File \u001b[0;32m~/mambaforge/envs/py310/lib/python3.10/site-packages/milvus/__init__.py:395\u001b[0m, in \u001b[0;36mMilvusServer.wait_started\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    393\u001b[0m         sleep(\u001b[39m0.1\u001b[39m)\n\u001b[1;32m    394\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrunning:\n\u001b[0;32m--> 395\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTimeoutError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mMilvus not startd in \u001b[39m\u001b[39m{\u001b[39;00mtimeout\u001b[39m/\u001b[39m\u001b[39m1000\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m seconds\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    396\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    397\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mMilvus server already stopped\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mTimeoutError\u001b[0m: Milvus not startd in 180.0 seconds"
     ]
    }
   ],
   "source": [
    "from milvus import default_server, debug_server\n",
    "from pymilvus import (\n",
    "    connections, utility, FieldSchema, \n",
    "    DataType, CollectionSchema, Collection)\n",
    "\n",
    "# Cleanup previous data and stop server in case it is still running.\n",
    "default_server.stop()\n",
    "default_server.cleanup()\n",
    "\n",
    "# Start a new milvus-lite local server.\n",
    "start_time = time.time()\n",
    "default_server.start()\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"startup time: {end_time - start_time}\")\n",
    "# startup time: 5.6739208698272705\n",
    "\n",
    "# Add wait to avoid error message from trying to connect.\n",
    "time.sleep(15)\n",
    "\n",
    "# Now you could connect with localhost and the given port.\n",
    "# Port is defined by default_server.listen_port.\n",
    "connections.connect(host='127.0.0.1', \n",
    "                  port=default_server.listen_port,\n",
    "                  show_startup_banner=True)\n",
    "\n",
    "# Check if the server is ready.\n",
    "print(utility.get_server_version())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2b12728",
   "metadata": {},
   "source": [
    "**Create a Milvus collection**\n",
    "\n",
    "You can think of a collection in Milvus like a \"table\" in SQL databases.  The **collection** will contain the \n",
    "- Schema\n",
    "- Index to raw data segments\n",
    "- Search index for efficient vector search\n",
    "\n",
    "Some supported [data types](https://milvus.io/docs/schema.md) for Milvus schemas are:\n",
    "- INT64 - primary key\n",
    "- VARCHAR - raw texts\n",
    "- FLOAT_VECTOR - embedings = list of `numpy.ndarray` of `numpy.float32` numbers\n",
    "\n",
    "To finish specifying the schema, you'll need to get the vector `EMBEDDING_LENGTH` and `MAX_SEQ_LENGTH` parameters from your embedding model.\n",
    "\n",
    "Transactional consistency is possible; however, according to the [CAP theorem](https://en.wikipedia.org/wiki/CAP_theorem), some latency must be sacrificed.  \n",
    "- Searching movie reviews is not mission-critical, so [`eventually`](https://milvus.io/docs/consistency.md) consistent is fine here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a85b295",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the length of the embedding vectors.\n",
    "EMBEDDING_LENGTH = 768\n",
    "\n",
    "# Set the maximum length of the text sequences.\n",
    "# This is used to pad/truncate the sequences, so they all have the same length.\n",
    "# Usually set to the embedding model's sequence length, but milvus should not care.\n",
    "MAX_SEQ_LENGTH = 65535 # milvus internal limit; our model has 512 limit\n",
    "\n",
    "# Set the Milvus collection name.\n",
    "COLLECTION_NAME = \"movies\"\n",
    "\n",
    "# Create a collection with 6 fields.\n",
    "fields = [\n",
    "    FieldSchema(name=\"pk\", dtype=DataType.INT64, is_primary=True, auto_id=True),\n",
    "    FieldSchema(name=\"movie_index\", dtype=DataType.VARCHAR, max_length=8),\n",
    "    FieldSchema(name=\"chunk\", dtype=DataType.VARCHAR, max_length=MAX_SEQ_LENGTH),\n",
    "    FieldSchema(name=\"embeddings\", dtype=DataType.FLOAT_VECTOR, dim=EMBEDDING_LENGTH),\n",
    "    FieldSchema(name=\"label_int\", dtype=DataType.INT64),\n",
    "    FieldSchema(name=\"label\", dtype=DataType.VARCHAR, max_length=8),\n",
    "]\n",
    "\n",
    "schema = CollectionSchema(fields, \"Search imdb movie reviews\")\n",
    "mc = Collection(COLLECTION_NAME, schema, consistency_level=\"Eventually\")\n",
    "print(f\"Created collection: {COLLECTION_NAME}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46de56ab",
   "metadata": {},
   "source": [
    "**Add a Search Index**\n",
    "\n",
    "The search index determines the vector **search algorithm** used to find the closest vectors in your data to the query a user submits.  Scroll down the [docs page](https://milvus.io/docs/index.md) to see a table listing different search indexes available on Milvus.  For example:\n",
    "- FLAT - Hash index (deterministic exhaustive search)\n",
    "- IVF_FLAT - Hash index (deterministic exhaustive search)\n",
    "- HNSW - Graph index (stochastic approximate search)\n",
    "- ANNOY - Tree index (stochastic approximate search)\n",
    "\n",
    "Besides a search algorithm, we also need to specify a **distance metric**, that is, a definition of what is considered \"close\" in vector space.  In the cell below, the [`HNSW`](https://github.com/nmslib/hnswlib/blob/master/ALGO_PARAMS.md) search index is chosen.  Its possible distance metrics are one of:\n",
    "- L2 - L2-norm\n",
    "- IP - Dot-product\n",
    "- COSINE - Angular distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15572c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the type of search index to add to the collection.\n",
    "\n",
    "# # Note: on Zilliz Cloud - Proprietary index is fastest!\n",
    "# index_params = {\n",
    "#     # Always set this to AUTOINDEX or just omit it.\n",
    "#     \"index_type\": \"AUTOINDEX\", \n",
    "#     # Default to IP. This is the only parameter you need to think about.\n",
    "#     \"metric_type\": \"COSINE\",\n",
    "# }\n",
    "\n",
    "# Drop the index, in case it already exists.\n",
    "mc.drop_index()\n",
    "\n",
    "# Create the search index for local Milvus server.\n",
    "# Showing how to change the index parameters, instead of using defaults.\n",
    "index_params = {\n",
    "    \"index_type\": \"HNSW\", \n",
    "    \"metric_type\": \"COSINE\", \n",
    "    \"params\": {'M': 16,               # int. 4~64, num_layers\n",
    "               \"efConstruction\": 32}  # int. 8~512, num_nearest_neighbors\n",
    "               }\n",
    "mc.create_index(\"embeddings\", index_params);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e735fe08",
   "metadata": {},
   "source": [
    "## Read CSV data into a pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a381e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read locally stored data.\n",
    "filepath = \"data/movie_data.csv\"\n",
    "\n",
    "df = pd.read_csv(f\"{filepath}\")\n",
    "\n",
    "# Drop duplicates\n",
    "df.drop_duplicates(keep='first', inplace=True)\n",
    "\n",
    "# Change label column names.\n",
    "df.columns = ['text', 'label_int']\n",
    "\n",
    "# Map numbers to text 'Postive' and 'Negative' for sentiment labels.\n",
    "df[\"label\"] = df[\"label_int\"].apply(sentiment_score_to_name)\n",
    "\n",
    "# Split data into train/valid/test.\n",
    "df, df_train, df_val, df_test = partition_dataset(df, smoke_test=False)\n",
    "print(f\"original df shape: {df.shape}\")\n",
    "print(f\"df_train shape: {df_train.shape}, df_val shape: {df_val.shape}, df_test shape: {df_test.shape}\")\n",
    "assert df_train.shape[0] + df_val.shape[0] + df_test.shape[0] == df.shape[0]\n",
    "\n",
    "# Inspect data.\n",
    "print(f\"Example text length: {len(df.text[0])}\")\n",
    "print(f\"Example text: {df.text[0]}\")\n",
    "display(df.head(2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "654dd135",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if approx. equal number training examples for each class.\n",
    "class1 = df_train.loc[(df_train.label == \"Positive\"), :].copy()\n",
    "class2 = df_train.loc[(df_train.label == \"Negative\"), :].copy()\n",
    "print(f\"Count samples positive: {class1.shape[0]}\")\n",
    "print(f\"Count samples negative: {class2.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dccbda2f",
   "metadata": {},
   "source": [
    "## Load the Embedding Model checkpoint and use it to create vector embeddings\n",
    "**Embedding model:**  We will use the open-source [sentence transformers](https://www.sbert.net/docs/pretrained_models.html) hosted on HuggingFace to encode the movie review text.  We will save the embeddings to a pandas dataframe and then into the milvus database.\n",
    "\n",
    "**Chunking:** Before embedding, it is necessary to decide your chunk and chunk overlap sizes.  In this hello_world demo, I will use `MAX_SEQ_LENGTH` for chunk size.\n",
    "\n",
    "Note:  To keep your tokens private, best practice is to use an env variable.   <br>\n",
    "In Jupyter, need .env file (in same dir as notebooks) containing lines like this:\n",
    "- VARIABLE_NAME=value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54790248-916b-4cc2-bc22-36cbdca4baf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import torch.\n",
    "import torch\n",
    "from torch.nn import functional as F\n",
    "\n",
    "# Initialize torch settings\n",
    "torch.backends.cudnn.deterministic = True\n",
    "RANDOM_SEED = 415\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "DEVICE = torch.device('cuda:3' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"device: {DEVICE}\")\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "from huggingface_hub import login\n",
    "\n",
    "# Login to huggingface_hub\n",
    "hub_token = os.getenv(\"HUGGINGFACEHUB_API_TOKEN\")\n",
    "login(token=hub_token)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e0cc471",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Load the model from huggingface model hub.\n",
    "model_name = \"BAAI/bge-base-en-v1.5\"\n",
    "retriever = SentenceTransformer(model_name, device=DEVICE)\n",
    "print(type(retriever))\n",
    "print(retriever)\n",
    "\n",
    "# Get the model parameters and save for later.\n",
    "MAX_SEQ_LENGTH = retriever.get_max_seq_length() \n",
    "HF_EOS_TOKEN_LENGTH = 1\n",
    "HF_TOKEN_EOS_LENGTH = 1\n",
    "EMBEDDING_LENGTH = retriever.get_sentence_embedding_dimension()\n",
    "\n",
    "# Inspect model parameters.\n",
    "print(f\"model_name: {model_name}\")\n",
    "print(f\"EMBEDDING_LENGTH: {EMBEDDING_LENGTH}\")\n",
    "print(f\"MAX_SEQ_LENGTH: {MAX_SEQ_LENGTH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a53595fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "chunk_size = MAX_SEQ_LENGTH - HF_TOKEN_EOS_LENGTH\n",
    "chunk_overlap = np.round(chunk_size * 0.10, 0)\n",
    "print(f\"chunk_size: {chunk_size}, overlap: {chunk_overlap}\")\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=chunk_size,\n",
    "    chunk_overlap=chunk_overlap,\n",
    "    length_function=len,\n",
    ")\n",
    "\n",
    "def chunk_text(text):\n",
    "    chunks = text_splitter.split_text(text)\n",
    "    return [chunk for chunk in chunks if chunk]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "249e9c74",
   "metadata": {},
   "source": [
    "**Only inserting 100 rows for demonstration purposes.**\n",
    "\n",
    "This means the query results likely will not be very good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f915aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare df for insertion into Milvus index.\n",
    "# TODO - move all this to a utility function.\n",
    "\n",
    "# Batch of data from pandas DataFrame.\n",
    "batch = df.head(100).copy()  \n",
    "\n",
    "# 1. Change primary key type to string.\n",
    "batch[\"movie_index\"] = batch[\"movie_index\"].apply(lambda x: str(x))\n",
    "\n",
    "# 2. Truncate reviews to 512 characters.\n",
    "# batch[\"text\"] = batch[\"text\"].apply(lambda x: x[:MAX_SEQ_LENGTH - HF_EOS_TOKEN_LENGTH])\n",
    "batch['chunk'] = batch['text'].apply(chunk_text)\n",
    "# Explode the 'characters' column to create new rows for each character\n",
    "batch = batch.explode('chunk', ignore_index=True)\n",
    "\n",
    "# 3. Add embeddings as new column in df.\n",
    "review_embeddings = torch.tensor(retriever.encode(batch['chunk']))\n",
    "# Normalize embeddings to unit length.\n",
    "review_embeddings = F.normalize(review_embeddings, p=2, dim=1)\n",
    "# Quick check if embeddings are normalized.\n",
    "norms = np.linalg.norm(review_embeddings, axis=1)\n",
    "assert np.allclose(norms, 1.0, atol=1e-5) == True\n",
    "\n",
    "# 4. Convert embeddings to list of `numpy.ndarray`, each containing `numpy.float32` numbers.\n",
    "converted_values = list(map(np.float32, review_embeddings))\n",
    "batch['embeddings'] = converted_values\n",
    "\n",
    "# 5. Reorder columns for conveneince, so index first, labels at end.\n",
    "new_order = [\"movie_index\", \"text\", \"chunk\", \"embeddings\", \"label_int\", \"label\"]\n",
    "batch = batch[new_order]\n",
    "\n",
    "# Inspect data.\n",
    "display(batch.head(2))\n",
    "assert len(batch.chunk[0]) <= MAX_SEQ_LENGTH-1\n",
    "assert len(batch.embeddings[0]) == EMBEDDING_LENGTH\n",
    "print(f\"type embeddings: {type(batch.embeddings)} of {type(batch.embeddings[0])}\")\n",
    "print(f\"of numbers: {type(batch.embeddings[0][0])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6233d309",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect chunking of the data.\n",
    "print(\"original\")\n",
    "print(df.loc[(df.movie_index==931), \"text\"])\n",
    "print(\"chunked\")\n",
    "checkit = list(batch.loc[(batch.movie_index==\"931\"), \"chunk\"])\n",
    "[print(chunk) for chunk in checkit]\n",
    "\n",
    "# Chunking looks good, drop the original text column.\n",
    "batch.drop(columns=[\"text\"], inplace=True)\n",
    "batch.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9bd8153",
   "metadata": {},
   "source": [
    "## Insert data into Milvus\n",
    "\n",
    "We can insert data directly from a pandas dataframe into Milvus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b51ff139",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert data into the Milvus collection.\n",
    "print(\"Start inserting entities\")\n",
    "insert_result = mc.insert(batch)\n",
    "\n",
    "# After final entity is inserted, call flush to stop growing segments left in memory.\n",
    "mc.flush() \n",
    "\n",
    "# Inspect results.\n",
    "print(insert_result)\n",
    "print(mc.partitions) # list[Partition] objects"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ebfb115",
   "metadata": {},
   "source": [
    "## Run a Semantic Search\n",
    "\n",
    "Now we can search all the movie review embeddings to find the `TOP_K` movie reviews with the closest embeddings to a user's question.\n",
    "- In this example, we'll search for a movie recommendation for a medical doctor.\n",
    "\n",
    "Note:  The same model should always be used for consistency for all the embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb7bc132",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before conducting a search or a query, you need to load the data into memory.\n",
    "mc.load()\n",
    "print(\"Loaded milvus collection into memory.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02c589ff",
   "metadata": {},
   "source": [
    "**Ask a question about your data**\n",
    "\n",
    "Your custom data is mapped into a vector embedding space and those vector embeddings are saved into a vector database.  \n",
    "\n",
    "Next, you can ask a question about your custom data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e7f41f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a sample question about your data.\n",
    "query = \"I'm a medical doctor, what movie should I watch?\"\n",
    "\n",
    "# Inspect the length of the query.\n",
    "QUERY_LENGTH = len(query)\n",
    "print(f\"query length: {QUERY_LENGTH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa545611",
   "metadata": {},
   "source": [
    "**Embed the query using the same embedding model you used earlier**\n",
    "\n",
    "In order for vector search to work, the query itself should be embedded with the same model used to create the colleciton you want to search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6863a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embed the query using same embedding model used to create the Milvus collection.\n",
    "query_embeddings = torch.tensor(retriever.encode([query]))\n",
    "# Normalize embeddings to unit length.\n",
    "query_embeddings = torch.nn.functional.normalize(query_embeddings, p=2, dim=1)\n",
    "# Quick check if embeddings are normalized.\n",
    "norms = np.linalg.norm(query_embeddings, axis=1)\n",
    "assert np.allclose(norms, 1.0, atol=1e-5) == True\n",
    "\n",
    "# Convert the embeddings to list of list of np.float32.\n",
    "query_embeddings = list(map(np.float32, query_embeddings))\n",
    "\n",
    "# Inspect data.\n",
    "print(type(query_embeddings), len(query_embeddings), type(query_embeddings[0]))\n",
    "print(type(query_embeddings[0][0]) ) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ea29411",
   "metadata": {},
   "source": [
    "## Execute a vector search\n",
    "\n",
    "https://milvus.io/docs/search.md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d98e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute a search.\n",
    "\n",
    "# Return top k results with HNSW index.\n",
    "TOP_K = 3\n",
    "search_params = {\n",
    "    \"M\": 16,\n",
    "    \"ef\": 32,\n",
    "}\n",
    "\n",
    "start_time = time.time()\n",
    "results = mc.search(\n",
    "    data=query_embeddings, \n",
    "    anns_field=\"embeddings\", \n",
    "    param=search_params,\n",
    "    output_fields=[\"movie_index\", \"chunk\", \"label\"], \n",
    "    limit=TOP_K,\n",
    "    consistency_level=\"Eventually\"\n",
    "    )\n",
    "\n",
    "elapsed_time = time.time() - start_time\n",
    "print(elapsed_time)\n",
    "\n",
    "print(f\"type: {type(results)}, count: {len(results[0])}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95f7e011",
   "metadata": {},
   "source": [
    "## Assemble and inspect the query result\n",
    "\n",
    "The query result is in the variable `result[0]` of type `'pymilvus.orm.search.SearchResult'`.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3dfa33a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the distances to the query vector from all returned hits\n",
    "distances = results[0].distances\n",
    "\n",
    "# Get the movie_indexes, review texts, and labels.\n",
    "texts = []\n",
    "movie_indexes = []\n",
    "labels = []\n",
    "for result in results[0]:\n",
    "    texts.append(result.entity.get(\"chunk\"))\n",
    "    movie_indexes.append(result.entity.get(\"movie_index\"))\n",
    "    # movie_indexes.append(0)\n",
    "    labels.append(result.entity.get(\"label\"))\n",
    "    # labels.append(\"Positive\")\n",
    "\n",
    "# Assemble all the results in a zipped list.\n",
    "print_info = list(zip(distances, movie_indexes, texts, labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d65363",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the results.\n",
    "# k: distance, movie_index, label, review text\n",
    "\n",
    "i = 0\n",
    "for row in print_info:\n",
    "    # print(row)\n",
    "    print(f\"{i}: {np.round(row[0],3)}, {row[1]}, {row[3]}, {row[2][:100]}\")\n",
    "    i += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e81e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shut down and cleanup the milvus server.\n",
    "default_server.stop()\n",
    "default_server.cleanup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c777937e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext watermark\n",
    "%watermark -a 'Christy Bergman' -v -p torch,transformers,milvus,pymilvus,langchain --conda"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
