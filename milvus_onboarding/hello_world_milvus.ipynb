{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "369c3444",
   "metadata": {},
   "source": [
    "# Load embedding data into Milvus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ffd11a",
   "metadata": {},
   "source": [
    "First, import some common libraries and define the data reading functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7570b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries.\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Output words instead of scores.\n",
    "def sentiment_score_to_name(score: float):\n",
    "    if score > 0:\n",
    "        return \"Positive\"\n",
    "    elif score <= 0:\n",
    "        return \"Negative\"\n",
    "    \n",
    "def partition_dataset(df_input, smoke_test=False):\n",
    "    \"\"\"Splits data, assuming original, input dataframe contains 50K rows.\n",
    "\n",
    "    Args:\n",
    "        df_input (pandas.DataFrame): input data frame\n",
    "        smoke_test (boolean): if True, use smaller number of rows for testing\n",
    "    \n",
    "    Returns:\n",
    "        df_train, df_val, df_test (pandas.DataFrame): train, valid, test splits.\n",
    "    \"\"\"\n",
    "\n",
    "    # Shuffle data and split into train/val/test.\n",
    "    df_shuffled = df_input.sample(frac=1, random_state=1).reset_index()\n",
    "    # Add a corpus index.\n",
    "    columns = ['movie_index', 'text', 'label_int', 'label']\n",
    "    df_shuffled.columns = columns\n",
    "\n",
    "    df_train = df_shuffled.iloc[:35_000]\n",
    "    df_val = df_shuffled.iloc[35_000:40_000]\n",
    "    df_test = df_shuffled.iloc[40_000:]\n",
    "\n",
    "    # Save train/val/test split data locally in separate files.\n",
    "    df_train.to_csv(\"train.csv\", index=False, encoding=\"utf-8\")\n",
    "    df_val.to_csv(\"val.csv\", index=False, encoding=\"utf-8\")\n",
    "    df_test.to_csv(\"test.csv\", index=False, encoding=\"utf-8\")\n",
    "\n",
    "    if smoke_test: \n",
    "        # Create small smoke_test datasets for easier testing purposes.\n",
    "        df_train_small = df_train.copy()\n",
    "        df_train_small = pd.concat([class1.iloc[0:100,:], class2.iloc[0:100,:]],\n",
    "                        join=\"outer\",\n",
    "                        ignore_index=True)\n",
    "        df_train_small.to_csv(\"train-small.csv\", index=False, encoding=\"utf-8\")\n",
    "\n",
    "        df_val_small = df_val.copy()\n",
    "        df_val_small = df_val.head(100)\n",
    "        df_val_small.to_csv(\"val-small.csv\", index=False, encoding=\"utf-8\")\n",
    "\n",
    "        df_test_small = df_test.copy()\n",
    "        df_test_small = df_test.head(8)\n",
    "        df_test_small.to_csv(\"test-small.csv\", index=False, encoding=\"utf-8\")\n",
    "\n",
    "        # Concatenate together so df_small has consistent corpus_index.\n",
    "        df_small = pd.concat([df_train_small, df_val_small, df_test_small],\n",
    "                        join=\"outer\",\n",
    "                        ignore_index=True)\n",
    "        return df_small, df_train_small, df_val_small, df_test_small\n",
    "\n",
    "    return df_shuffled, df_train, df_val, df_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a67e382",
   "metadata": {},
   "source": [
    "## Start up a local Milvus server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4f308ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://milvus.io/docs/example_code.md\n",
    "# https://pymilvus.readthedocs.io/en/latest/tutorial.html\n",
    "\n",
    "# !wget https://raw.githubusercontent.com/milvus-io/pymilvus/master/examples/hello_milvus.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb844837",
   "metadata": {},
   "source": [
    "Code in this notebook uses [Milvus lite](https://milvus.io/docs/milvus_lite.md), which runs a local server.  â›”ï¸ Milvus lite is only meant for demos and local testing.\n",
    "- pip install milvus pymilvus\n",
    "\n",
    "ðŸ’¡ **For production purposes**, use a local Milvus docker, Milvus clusters, or fully-managed Milvus on Zilliz Cloud.\n",
    "- [Local Milvus docker](https://milvus.io/docs/install_standalone-docker.md) requires local docker installed and running.\n",
    "- [Milvus clusters](https://milvus.io/docs/install_cluster-milvusoperator.md) requires a K8s cluster up and running.\n",
    "- [Ziliz Cloud free trial](https://cloud.zilliz.com/login)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "69acd0f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "startup time: 9.774549961090088\n",
      "v2.2-testing-20230824-68-ga34a9d606-lite\n"
     ]
    }
   ],
   "source": [
    "from milvus import default_server, debug_server\n",
    "from pymilvus import (\n",
    "    connections, utility, FieldSchema, \n",
    "    DataType, CollectionSchema, Collection)\n",
    "\n",
    "# Cleanup previous data and stop server in case it is still running.\n",
    "default_server.stop()\n",
    "default_server.cleanup()\n",
    "\n",
    "# Start a new milvus-lite local server.\n",
    "start_time = time.time()\n",
    "default_server.start()\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"startup time: {end_time - start_time}\")\n",
    "# startup time: 5.6739208698272705\n",
    "\n",
    "# Add wait to avoid error message from trying to connect.\n",
    "time.sleep(10)\n",
    "\n",
    "# Now you could connect with localhost and the given port.\n",
    "# Port is defined by default_server.listen_port.\n",
    "connections.connect(host='127.0.0.1', \n",
    "                  port=default_server.listen_port,\n",
    "                  show_startup_banner=True)\n",
    "\n",
    "# Check if the server is ready.\n",
    "print(utility.get_server_version())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e735fe08",
   "metadata": {},
   "source": [
    "## Read CSV data into a pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6a381e57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 2)\n",
      "(49582, 2)\n",
      "(49582, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label_int</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In 1974, the teenager Martha Moxley (Maggie Gr...</td>\n",
       "      <td>1</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>OK... so... I really like Kris Kristofferson a...</td>\n",
       "      <td>0</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>***SPOILER*** Do not read this, if you think a...</td>\n",
       "      <td>0</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hi for all the people who have seen this wonde...</td>\n",
       "      <td>1</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I recently bought the DVD, forgetting just how...</td>\n",
       "      <td>0</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label_int     label\n",
       "0  In 1974, the teenager Martha Moxley (Maggie Gr...          1  Positive\n",
       "1  OK... so... I really like Kris Kristofferson a...          0  Negative\n",
       "2  ***SPOILER*** Do not read this, if you think a...          0  Negative\n",
       "3  hi for all the people who have seen this wonde...          1  Positive\n",
       "4  I recently bought the DVD, forgetting just how...          0  Negative"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In 1974, the teenager Martha Moxley (Maggie Grace) moves to the high-class area of Belle Haven, Greenwich, Connecticut. On the Mischief Night, eve of Halloween, she was murdered in the backyard of her house and her murder remained unsolved. Twenty-two years later, the writer Mark Fuhrman (Christopher Meloni), who is a former LA detective that has fallen in disgrace for perjury in O.J. Simpson trial and moved to Idaho, decides to investigate the case with his partner Stephen Weeks (Andrew Mitchell) with the purpose of writing a book. The locals squirm and do not welcome them, but with the support of the retired detective Steve Carroll (Robert Forster) that was in charge of the investigation in the 70's, they discover the criminal and a net of power and money to cover the murder.<br /><br />\"Murder in Greenwich\" is a good TV movie, with the true story of a murder of a fifteen years old girl that was committed by a wealthy teenager whose mother was a Kennedy. The powerful and rich family used their influence to cover the murder for more than twenty years. However, a snoopy detective and convicted perjurer in disgrace was able to disclose how the hideous crime was committed. The screenplay shows the investigation of Mark and the last days of Martha in parallel, but there is a lack of the emotion in the dramatization. My vote is seven.<br /><br />Title (Brazil): Not Available (Rating: Positive)\n",
      "df: (49582, 4), train: (35000, 4), val: (5000, 4), test: (9582, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_index</th>\n",
       "      <th>text</th>\n",
       "      <th>label_int</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>26813</td>\n",
       "      <td>Fot the most part, this movie feels like a \"ma...</td>\n",
       "      <td>0</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>26581</td>\n",
       "      <td>Are you kidding me? The music was SO LOUD in t...</td>\n",
       "      <td>0</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movie_index                                               text  label_int  \\\n",
       "0        26813  Fot the most part, this movie feels like a \"ma...          0   \n",
       "1        26581  Are you kidding me? The music was SO LOUD in t...          0   \n",
       "\n",
       "      label  \n",
       "0  Negative  \n",
       "1  Negative  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read data after it has been stored locally\n",
    "filepath = \"movie_data.csv\"\n",
    "\n",
    "df = pd.read_csv(f\"{filepath}\")\n",
    "\n",
    "# Drop duplicates\n",
    "print(df.shape)\n",
    "df.drop_duplicates(keep='first', inplace=True)\n",
    "print(df.shape)\n",
    "\n",
    "# Change column names.\n",
    "df.columns = ['text', 'label_int']\n",
    "\n",
    "# Map numbers to text labels\n",
    "df[\"label\"] = df[\"label_int\"].apply(sentiment_score_to_name)\n",
    "\n",
    "# Append label to text for better rating classifier training.\n",
    "df['text'] = df['text'] + ' (Rating: ' + df['label'].astype(str) + ')'\n",
    "\n",
    "print(df.shape)     # (50000, 3)\n",
    "display(df.head())\n",
    "print(df.text[0])\n",
    "\n",
    "# Split data into train/valid/test.\n",
    "# See https://huggingface.co/docs/datasets/v1.4.0/add_dataset.html\n",
    "# This utility function splits and saves each file locally.\n",
    "# df, df_train, df_val, df_test = partition_dataset(df, smoke_test=True)\n",
    "df, df_train, df_val, df_test = partition_dataset(df, smoke_test=False)\n",
    "\n",
    "# Train/valid/test split assume 50K rows in original dataset.\n",
    "print(f\"df: {df.shape}, train: {df_train.shape}, val: {df_val.shape}, test: {df_test.shape}\")\n",
    "df.head(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "654dd135",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17606, 4) (17394, 4)\n"
     ]
    }
   ],
   "source": [
    "# Check if approx. equal number training examples for each class.\n",
    "class1 = df_train.loc[(df_train.label == \"Positive\"), :].copy()\n",
    "class2 = df_train.loc[(df_train.label == \"Negative\"), :].copy()\n",
    "print(class1.shape, class2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dccbda2f",
   "metadata": {},
   "source": [
    "### Initialize the Embedding Model and Vector DB\n",
    "**Embedding model:**  I will use an embedding model from [sentence transformers](https://www.sbert.net/docs/pretrained_models.html) hosted on huggingface to encode the movie review text.  Then, we will save the embeddings to the milvus database.\n",
    "\n",
    "**Chunking:** Before embedding, it is necessary to decide your chunk and chunk overlap sizes.  In this hello_world demo, I will use the Review text length itself as the chunk length.  Occasionally reviews are very long, but mostly they are short paragraphs.\n",
    "\n",
    "Note:  To keep your tokens private, best practice is to use an env variable.   <br>\n",
    "In Jupyter, need .env file (in same dir as notebooks) containing lines like this:\n",
    "- VARIABLE_NAME=value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "54790248-916b-4cc2-bc22-36cbdca4baf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cpu\n",
      "Token will not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n",
      "Token is valid (permission: write).\n",
      "Your token has been saved to /Users/christybergman/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "# Import torch.\n",
    "import torch\n",
    "\n",
    "# Initialize torch settings\n",
    "torch.backends.cudnn.deterministic = True\n",
    "RANDOM_SEED = 415\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "DEVICE = torch.device('cuda:3' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"device: {DEVICE}\")\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "from huggingface_hub import login\n",
    "\n",
    "# Login to huggingface_hub\n",
    "hub_token = os.getenv(\"HUGGINGFACEHUB_API_TOKEN\")\n",
    "login(token=hub_token)\n",
    "\n",
    "# Set tokenizers parallelism to false, to avoid issues with multiprocessing.\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5e0cc471",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sentence_transformers.SentenceTransformer.SentenceTransformer'>\n",
      "SentenceTransformer(\n",
      "  (0): Transformer({'max_seq_length': 512, 'do_lower_case': True}) with Transformer model: BertModel \n",
      "  (1): Pooling({'word_embedding_dimension': 768, 'pooling_mode_cls_token': True, 'pooling_mode_mean_tokens': False, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False})\n",
      ")\n",
      "model_name: BAAI/bge-base-en-v1.5\n",
      "embedding vector length: 768, max_seq_length: 512\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# load the retriever model from huggingface model hub\n",
    "model_name = \"BAAI/bge-base-en-v1.5\"\n",
    "retriever = SentenceTransformer(model_name, device=DEVICE)\n",
    "print(type(retriever))\n",
    "print(retriever)\n",
    "\n",
    "# Save params for later.\n",
    "max_seq_length = retriever.get_max_seq_length() \n",
    "EMBEDDING_LENGTH = retriever.get_sentence_embedding_dimension()\n",
    "print(f\"model_name: {model_name}\")\n",
    "print(f\"embedding vector length: {EMBEDDING_LENGTH}, max_seq_length: {max_seq_length}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0f915aed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_index</th>\n",
       "      <th>text</th>\n",
       "      <th>embeddings</th>\n",
       "      <th>label_int</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>26813</td>\n",
       "      <td>Fot the most part, this movie feels like a \"ma...</td>\n",
       "      <td>[-0.022307869, -0.038372956, -0.005369567, -0....</td>\n",
       "      <td>0</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>26581</td>\n",
       "      <td>Are you kidding me? The music was SO LOUD in t...</td>\n",
       "      <td>[-0.024203338, -0.028892132, -0.04505902, 0.01...</td>\n",
       "      <td>0</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  movie_index                                               text  \\\n",
       "0       26813  Fot the most part, this movie feels like a \"ma...   \n",
       "1       26581  Are you kidding me? The music was SO LOUD in t...   \n",
       "\n",
       "                                          embeddings  label_int     label  \n",
       "0  [-0.022307869, -0.038372956, -0.005369567, -0....          0  Negative  \n",
       "1  [-0.024203338, -0.028892132, -0.04505902, 0.01...          0  Negative  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "movie_index    object\n",
      "text           object\n",
      "embeddings     object\n",
      "label_int       int64\n",
      "label          object\n",
      "dtype: object\n",
      "type embeddings: <class 'numpy.ndarray'>, <class 'numpy.float32'>\n"
     ]
    }
   ],
   "source": [
    "# TODO - move all this to a utility function.\n",
    "# Prepare df for insertion into Milvus index.\n",
    "\n",
    "# Batch of data from pandas DataFrame.\n",
    "batch = df.head(5).copy()  # TODO - change back to 100 and put ths in a function.\n",
    "\n",
    "# 1. Change primary key type to string.\n",
    "batch[\"movie_index\"] = batch[\"movie_index\"].apply(lambda x: str(x))\n",
    "\n",
    "# 2. Truncate reviews to 512 characters.\n",
    "batch[\"text\"] = batch[\"text\"].apply(lambda x: x[:max_seq_length-1])\n",
    "\n",
    "# 3. Add embeddings as new column in df.\n",
    "review_embeddings = torch.tensor(retriever.encode(batch['text']))\n",
    "# Normalize embeddings to unit length.\n",
    "review_embeddings = torch.nn.functional.normalize(review_embeddings, p=2, dim=1)\n",
    "# Quick check if embeddings are normalized.\n",
    "norms = np.linalg.norm(review_embeddings, axis=1)\n",
    "assert np.allclose(norms, 1.0, atol=1e-5) == True\n",
    "\n",
    "# 4. Convert the embeddings to np.float32\n",
    "converted_values = list(map(np.float32, review_embeddings))\n",
    "batch['embeddings'] = converted_values\n",
    "\n",
    "# 5. Reorder columns so pk first, labels at end.\n",
    "new_order = [\"movie_index\", \"text\", \"embeddings\", \"label_int\", \"label\"]\n",
    "batch = batch[new_order]\n",
    "\n",
    "display(batch.head(2))\n",
    "assert len(batch.text[0]) == max_seq_length-1\n",
    "assert len(batch.embeddings[0]) == EMBEDDING_LENGTH\n",
    "print(batch.dtypes)\n",
    "print(f\"type embeddings: {type(batch.embeddings[0])}, {type(batch.embeddings[0][0])}\")\n",
    "\n",
    "# milvus field random, only supports list\n",
    "# milvus field embeddings, supports numpy.ndarray and list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aedb7f82",
   "metadata": {},
   "source": [
    "## Create a Milvus collection (\"table\") for the embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c00234c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created collection: movies\n"
     ]
    }
   ],
   "source": [
    "# Supported data types for Milvus are:\n",
    "# INT64\n",
    "# VARCHAR\n",
    "# VECTOR as FLOAT32 arrays\n",
    "\n",
    "# Note: One column of type DataType.FLOAT_VECTOR is mandatory!?\n",
    "fields = [\n",
    "    FieldSchema(name=\"movie_index\", dtype=DataType.VARCHAR, is_primary=True, auto_id=False, max_length=8),\n",
    "    FieldSchema(name=\"text\", dtype=DataType.VARCHAR, max_length=512),\n",
    "    FieldSchema(name=\"embeddings\", dtype=DataType.FLOAT_VECTOR, dim=EMBEDDING_LENGTH),\n",
    "    FieldSchema(name=\"label_int\", dtype=DataType.INT64),\n",
    "    FieldSchema(name=\"label\", dtype=DataType.VARCHAR, max_length=8),\n",
    "]\n",
    "\n",
    "collection_name = \"movies\"\n",
    "schema = CollectionSchema(fields, \"Search imdb movie reviews\")\n",
    "mc = Collection(collection_name, schema, consistency_level=\"Strong\")\n",
    "print(f\"Created collection: {collection_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b51ff139",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start inserting entities\n",
      "(insert count: 5, delete count: 0, upsert count: 0, timestamp: 444601275148664840, success count: 5, err count: 0)\n"
     ]
    }
   ],
   "source": [
    "# Insert data into the Milvus collection\n",
    "print(\"Start inserting entities\")\n",
    "insert_result = mc.insert(batch)\n",
    "\n",
    "# insert_result = hello_milvus.insert(entities)\n",
    "\n",
    "# After final entity is inserted, it is best to call flush to have no growing segments left in memory\n",
    "mc.flush() \n",
    "print(insert_result)\n",
    "# print(mc.partitions)            # Return the list[Partition] object.\n",
    "\n",
    "# 3.1 seconds for 100 rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "42018385",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Status(code=0, message=)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build an index on the Milvus collection.\n",
    "# Choice of index: https://milvus.io/docs/index.md\n",
    "# How to use HNSW: # https://github.com/nmslib/hnswlib/blob/master/ALGO_PARAMS.md\n",
    "# DISTANCE_METRIC: One of L2, IP, COSINE \n",
    "\n",
    "# # On Zilliz Cloud - Proprietary index is fastest!\n",
    "# index_params = {\n",
    "#     # Always set this to AUTOINDEX or just omit it.\n",
    "#     \"index_type\": \"AUTOINDEX\", \n",
    "#     # Default to IP. This is the only parameter you should think about.\n",
    "#     \"metric_type\": \"COSINE\",\n",
    "#     # No need to set `params`\n",
    "# }\n",
    "\n",
    "# Drop the index, just in case it exists.\n",
    "mc.drop_index()\n",
    "\n",
    "# Create the index.\n",
    "index_params = {\n",
    "    \"index_type\": \"HNSW\", \n",
    "    \"metric_type\": \"COSINE\", \n",
    "    \"params\": {'M': 16,               # int. 4~64, num_layers\n",
    "               \"efConstruction\": 32}  # int. 8~512, num_nearest_neighbors\n",
    "               }\n",
    "mc.create_index(\"embeddings\", index_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ebfb115",
   "metadata": {},
   "source": [
    "#### Run a Semantic Search\n",
    "\n",
    "With the database populated, it's now possible to search all of the movies based on their reviews. In this example, we search for a movie where ... . We get the embeddings for these docs, and then search our vector database for the 3 docs with the closest embeddings.\n",
    "\n",
    "Use a HuggingFace Retriever model to encode the question and search for top-k.\n",
    "\n",
    "This could be a different, or same model we used to create text encodings.  <br>\n",
    "Below, we'll keep the same model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "eb7bc132",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded milvus collection into memory.\n"
     ]
    }
   ],
   "source": [
    "# Before conducting a search or a query, you need to load the data in `hello_milvus` into memory.\n",
    "mc.load()\n",
    "print(\"Loaded milvus collection into memory.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a6863a32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query length: 45\n",
      "<class 'list'> 1 <class 'numpy.ndarray'>\n",
      "<class 'numpy.float32'>\n"
     ]
    }
   ],
   "source": [
    "# Define a typical question for length estimation purposes.\n",
    "query = 'Which index does Langchain Milvus default to?'\n",
    "QUERY_LENGTH = len(query)\n",
    "print(f\"query length: {QUERY_LENGTH}\")\n",
    "\n",
    "# Embed the query using same embedding model as used for the Milvus collection.\n",
    "query_embeddings = torch.tensor(retriever.encode([query]))\n",
    "# Normalize embeddings to unit length.\n",
    "query_embeddings = torch.nn.functional.normalize(query_embeddings, p=2, dim=1)\n",
    "# Quick check if embeddings are normalized.\n",
    "norms = np.linalg.norm(query_embeddings, axis=1)\n",
    "assert np.allclose(norms, 1.0, atol=1e-5) == True\n",
    "\n",
    "# Convert the embeddings to list of list of np.float32.\n",
    "query_embeddings = list(map(np.float32, query_embeddings))\n",
    "\n",
    "print(type(query_embeddings), len(query_embeddings), type(query_embeddings[0]))\n",
    "print(type(query_embeddings[0][0]) ) #, len(query_embeddings[0][0]))\n",
    "\n",
    "# type embeddings: <class 'numpy.ndarray'>, <class 'numpy.float32'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c5d98e28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.48792433738708496\n"
     ]
    }
   ],
   "source": [
    "# Execute a search.\n",
    "# https://milvus.io/docs/search.md\n",
    "\n",
    "top_k = 1  # return top k results\n",
    "search_params = {\n",
    "    \"M\": 16,\n",
    "    \"ef\": 32,\n",
    "}\n",
    "\n",
    "start_time = time.time()\n",
    "retrieved_documents = mc.search(data=query_embeddings, \n",
    "                      anns_field=\"embeddings\", \n",
    "                      param=search_params,\n",
    "                      output_fields=[\"text\"], \n",
    "                      limit=top_k)\n",
    "elapsed_time = time.time() - start_time\n",
    "print(elapsed_time)\n",
    "\n",
    "print(type(retrieved_documents), len(retrieved_documents))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "22d65363",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id: 13007, distance: 0.42943188548088074, entity: {\\'text\\': \"Saying this movie is extremely hard to follow and just as frustrating to sit through is putting it very mildly. Also saying that the current available print is dark, dreary, scratchy, abysmally edited, painfully dubbed, seemingly censored and in almost unwatchable shape is also correct. This film is in dire need of a good remastering from the full, uncut, original negative and seeing how it\\'s reasonably atmospheric (and won the director an award at the Catalonia Film Festival), it might actually be worth t\"}']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Saying this movie is extremely hard to follow and just as frustrating to sit through is putting it very mildly. Also saying that the current available print is dark, dreary, scratchy, abysmally edited, painfully dubbed, seemingly censored and in almost unwatchable shape is also correct. This film is in dire need of a good remastering from the full, uncut, original negative and seeing how it's reasonably atmospheric (and won the director an award at the Catalonia Film Festival), it might actually be worth t\""
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the results\n",
    "for result in retrieved_documents:\n",
    "    print(result)\n",
    "\n",
    "retrieved_documents[0][0].entity.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8e5fbdb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13007 <class 'str'>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_index</th>\n",
       "      <th>text</th>\n",
       "      <th>label_int</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13007</td>\n",
       "      <td>Saying this movie is extremely hard to follow ...</td>\n",
       "      <td>0</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movie_index                                               text  label_int  \\\n",
       "4        13007  Saying this movie is extremely hard to follow ...          0   \n",
       "\n",
       "      label  \n",
       "4  Negative  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id = retrieved_documents[0][0].id\n",
    "print(id, type(id))\n",
    "df.loc[df.movie_index == 13007, :]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c8595ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# query = \"What is a good movie for a medical doctor to watch?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c777937e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext watermark\n",
    "%watermark -a 'Christy Bergman' -v -p torch,transformers,milvus,langchain --conda"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
