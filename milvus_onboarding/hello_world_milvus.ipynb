{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "369c3444",
   "metadata": {},
   "source": [
    "# Embed Text Data & Load Vectors into Milvus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ffd11a",
   "metadata": {},
   "source": [
    "First, import some common libraries and define the data reading functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7570b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import common libraries.\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Output words instead of scores.\n",
    "def sentiment_score_to_name(score: float):\n",
    "    if score > 0:\n",
    "        return \"Positive\"\n",
    "    elif score <= 0:\n",
    "        return \"Negative\"\n",
    "\n",
    "# Split data into train, valid, test. \n",
    "def partition_dataset(df_input, smoke_test=False):\n",
    "    \"\"\"Splits data, assuming original, input dataframe contains 50K rows.\n",
    "\n",
    "    Args:\n",
    "        df_input (pandas.DataFrame): input data frame\n",
    "        smoke_test (boolean): if True, use smaller number of rows for testing\n",
    "    \n",
    "    Returns:\n",
    "        df_train, df_val, df_test (pandas.DataFrame): train, valid, test splits.\n",
    "    \"\"\"\n",
    "\n",
    "    # Shuffle data and split into train/val/test.\n",
    "    df_shuffled = df_input.sample(frac=1, random_state=1).reset_index()\n",
    "    # Add a corpus index.\n",
    "    columns = ['movie_index', 'text', 'label_int', 'label']\n",
    "    df_shuffled.columns = columns\n",
    "\n",
    "    df_train = df_shuffled.iloc[:35_000]\n",
    "    df_val = df_shuffled.iloc[35_000:40_000]\n",
    "    df_test = df_shuffled.iloc[40_000:]\n",
    "\n",
    "    # Save train/val/test split data locally in separate files.\n",
    "    df_train.to_csv(\"train.csv\", index=False, encoding=\"utf-8\")\n",
    "    df_val.to_csv(\"val.csv\", index=False, encoding=\"utf-8\")\n",
    "    df_test.to_csv(\"test.csv\", index=False, encoding=\"utf-8\")\n",
    "\n",
    "    return df_shuffled, df_train, df_val, df_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a67e382",
   "metadata": {},
   "source": [
    "## Start up a local Milvus server."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb844837",
   "metadata": {},
   "source": [
    "Code in this notebook uses [Milvus lite](https://milvus.io/docs/milvus_lite.md), which runs a local server.  â›”ï¸ Milvus lite is only meant for demos and local testing.\n",
    "- pip install milvus pymilvus\n",
    "\n",
    "ðŸ’¡ **For production purposes**, use a local Milvus docker, Milvus clusters, or fully-managed Milvus on Zilliz Cloud.\n",
    "- [Local Milvus docker](https://milvus.io/docs/install_standalone-docker.md) requires local docker installed and running.\n",
    "- [Milvus clusters](https://milvus.io/docs/install_cluster-milvusoperator.md) requires a K8s cluster up and running.\n",
    "- [Ziliz Cloud free trial](https://cloud.zilliz.com/login) choose a \"free\" option when you provision.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "69acd0f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "startup time: 5.264256000518799\n",
      "v2.2-testing-20230824-68-ga34a9d606-lite\n"
     ]
    }
   ],
   "source": [
    "from milvus import default_server, debug_server\n",
    "from pymilvus import (\n",
    "    connections, utility, FieldSchema, \n",
    "    DataType, CollectionSchema, Collection)\n",
    "\n",
    "# Cleanup previous data and stop server in case it is still running.\n",
    "default_server.stop()\n",
    "default_server.cleanup()\n",
    "\n",
    "# Start a new milvus-lite local server.\n",
    "start_time = time.time()\n",
    "default_server.start()\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"startup time: {end_time - start_time}\")\n",
    "# startup time: 5.6739208698272705\n",
    "\n",
    "# Add wait to avoid error message from trying to connect.\n",
    "time.sleep(15)\n",
    "\n",
    "# Now you could connect with localhost and the given port.\n",
    "# Port is defined by default_server.listen_port.\n",
    "connections.connect(host='127.0.0.1', \n",
    "                  port=default_server.listen_port,\n",
    "                  show_startup_banner=True)\n",
    "\n",
    "# Check if the server is ready.\n",
    "print(utility.get_server_version())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2b12728",
   "metadata": {},
   "source": [
    "**Create a Milvus collection**\n",
    "\n",
    "You can think of a collection in Milvus like a \"table\" in SQL databases.  The **collection** will contain the \n",
    "- Schema\n",
    "- Index to raw data segments\n",
    "- Search index for efficient vector search\n",
    "\n",
    "Some supported [data types](https://milvus.io/docs/schema.md) for Milvus schemas are:\n",
    "- INT64 - primary key\n",
    "- VARCHAR - raw texts\n",
    "- FLOAT_VECTOR - embedings = list of `numpy.ndarray` of `numpy.float32` numbers\n",
    "\n",
    "To finish specifying the schema, you'll need to get the vector `EMBEDDING_LENGTH` and `MAX_SEQ_LENGTH` parameters from your embedding model.\n",
    "\n",
    "Transactional consistency is possible; however, according to the [CAP theorem](https://en.wikipedia.org/wiki/CAP_theorem), some latency must be sacrificed.  \n",
    "- Searching movie reviews is not mission-critical, so [`eventually`](https://milvus.io/docs/consistency.md) consistent is fine here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a85b295",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created collection: movies\n"
     ]
    }
   ],
   "source": [
    "# Set the length of the embedding vectors.\n",
    "EMBEDDING_LENGTH = 768\n",
    "\n",
    "# Set the maximum length of the text sequences.\n",
    "# This is used to pad/truncate the sequences, so they all have the same length.\n",
    "# Usually set to the embedding model's sequence length, but milvus should not care.\n",
    "MAX_SEQ_LENGTH = 65535 # milvus internal limit; our model has 512 limit\n",
    "\n",
    "# Set the Milvus collection name.\n",
    "COLLECTION_NAME = \"movies\"\n",
    "\n",
    "# Create a collection with 6 fields.\n",
    "fields = [\n",
    "    FieldSchema(name=\"pk\", dtype=DataType.INT64, is_primary=True, auto_id=True),\n",
    "    FieldSchema(name=\"movie_index\", dtype=DataType.VARCHAR, max_length=8),\n",
    "    FieldSchema(name=\"chunk\", dtype=DataType.VARCHAR, max_length=MAX_SEQ_LENGTH),\n",
    "    FieldSchema(name=\"embeddings\", dtype=DataType.FLOAT_VECTOR, dim=EMBEDDING_LENGTH),\n",
    "    FieldSchema(name=\"label_int\", dtype=DataType.INT64),\n",
    "    FieldSchema(name=\"label\", dtype=DataType.VARCHAR, max_length=8),\n",
    "]\n",
    "\n",
    "schema = CollectionSchema(fields, \"Search imdb movie reviews\")\n",
    "mc = Collection(COLLECTION_NAME, schema, consistency_level=\"Eventually\")\n",
    "print(f\"Created collection: {COLLECTION_NAME}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46de56ab",
   "metadata": {},
   "source": [
    "**Add a Search Index**\n",
    "\n",
    "The search index determines the vector **search algorithm** used to find the closest vectors in your data to the query a user submits.  Scroll down the [docs page](https://milvus.io/docs/index.md) to see a table listing different search indexes available on Milvus.  For example:\n",
    "- FLAT - Hash index (deterministic exhaustive search)\n",
    "- IVF_FLAT - Hash index (deterministic exhaustive search)\n",
    "- HNSW - Graph index (stochastic approximate search)\n",
    "- ANNOY - Tree index (stochastic approximate search)\n",
    "\n",
    "Besides a search algorithm, we also need to specify a **distance metric**, that is, a definition of what is considered \"close\" in vector space.  In the cell below, the [`HNSW`](https://github.com/nmslib/hnswlib/blob/master/ALGO_PARAMS.md) search index is chosen.  Its possible distance metrics are one of:\n",
    "- L2 - L2-norm\n",
    "- IP - Dot-product\n",
    "- COSINE - Angular distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "15572c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the type of search index to add to the collection.\n",
    "\n",
    "# # Note: on Zilliz Cloud - Proprietary index is fastest!\n",
    "# index_params = {\n",
    "#     # Always set this to AUTOINDEX or just omit it.\n",
    "#     \"index_type\": \"AUTOINDEX\", \n",
    "#     # Default to IP. This is the only parameter you need to think about.\n",
    "#     \"metric_type\": \"COSINE\",\n",
    "# }\n",
    "\n",
    "# Drop the index, in case it already exists.\n",
    "mc.drop_index()\n",
    "\n",
    "# Create the search index for local Milvus server.\n",
    "# Showing how to change the index parameters, instead of using defaults.\n",
    "index_params = {\n",
    "    \"index_type\": \"HNSW\", \n",
    "    \"metric_type\": \"COSINE\", \n",
    "    \"params\": {'M': 16,               # int. 4~64, num_layers\n",
    "               \"efConstruction\": 32}  # int. 8~512, num_nearest_neighbors\n",
    "               }\n",
    "mc.create_index(\"embeddings\", index_params);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e735fe08",
   "metadata": {},
   "source": [
    "## Read CSV data into a pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6a381e57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original df shape: (49582, 4)\n",
      "df_train shape: (35000, 4), df_val shape: (5000, 4), df_test shape: (9582, 4)\n",
      "Example text length: 677\n",
      "Example text: Fot the most part, this movie feels like a \"made-for-TV\" effort. The direction is ham-fisted, the acting (with the exception of Fred Gwynne) is overwrought and soapy. Denise Crosby, particularly, delivers her lines like she's cold reading them off a cue card. Only one thing makes this film worth watching, and that is once Gage comes back from the \"Semetary.\" There is something disturbing about watching a small child murder someone, and this movie might be more than some can handle just for that reason. It is absolutely bone-chilling. This film only does one thing right, but it knocks that one thing right out of the park. Worth seeing just for the last 10 minutes or so.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_index</th>\n",
       "      <th>text</th>\n",
       "      <th>label_int</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>26813</td>\n",
       "      <td>Fot the most part, this movie feels like a \"ma...</td>\n",
       "      <td>0</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>26581</td>\n",
       "      <td>Are you kidding me? The music was SO LOUD in t...</td>\n",
       "      <td>0</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movie_index                                               text  label_int  \\\n",
       "0        26813  Fot the most part, this movie feels like a \"ma...          0   \n",
       "1        26581  Are you kidding me? The music was SO LOUD in t...          0   \n",
       "\n",
       "      label  \n",
       "0  Negative  \n",
       "1  Negative  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Read locally stored data.\n",
    "filepath = \"data/movie_data.csv\"\n",
    "\n",
    "df = pd.read_csv(f\"{filepath}\")\n",
    "\n",
    "# Drop duplicates\n",
    "df.drop_duplicates(keep='first', inplace=True)\n",
    "\n",
    "# Change label column names.\n",
    "df.columns = ['text', 'label_int']\n",
    "\n",
    "# Map numbers to text 'Postive' and 'Negative' for sentiment labels.\n",
    "df[\"label\"] = df[\"label_int\"].apply(sentiment_score_to_name)\n",
    "\n",
    "# Split data into train/valid/test.\n",
    "df, df_train, df_val, df_test = partition_dataset(df, smoke_test=False)\n",
    "print(f\"original df shape: {df.shape}\")\n",
    "print(f\"df_train shape: {df_train.shape}, df_val shape: {df_val.shape}, df_test shape: {df_test.shape}\")\n",
    "assert df_train.shape[0] + df_val.shape[0] + df_test.shape[0] == df.shape[0]\n",
    "\n",
    "# Inspect data.\n",
    "print(f\"Example text length: {len(df.text[0])}\")\n",
    "print(f\"Example text: {df.text[0]}\")\n",
    "display(df.head(2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "654dd135",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count samples positive: 17606\n",
      "Count samples negative: 17394\n"
     ]
    }
   ],
   "source": [
    "# Check if approx. equal number training examples for each class.\n",
    "class1 = df_train.loc[(df_train.label == \"Positive\"), :].copy()\n",
    "class2 = df_train.loc[(df_train.label == \"Negative\"), :].copy()\n",
    "print(f\"Count samples positive: {class1.shape[0]}\")\n",
    "print(f\"Count samples negative: {class2.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dccbda2f",
   "metadata": {},
   "source": [
    "## Load the Embedding Model checkpoint and use it to create vector embeddings\n",
    "**Embedding model:**  We will use the open-source [sentence transformers](https://www.sbert.net/docs/pretrained_models.html) hosted on HuggingFace to encode the movie review text.  We will save the embeddings to a pandas dataframe and then into the milvus database.\n",
    "\n",
    "**Chunking:** Before embedding, it is necessary to decide your chunk and chunk overlap sizes.  In this hello_world demo, I will use `MAX_SEQ_LENGTH` for chunk size.\n",
    "\n",
    "Note:  To keep your tokens private, best practice is to use an env variable.   <br>\n",
    "In Jupyter, need .env file (in same dir as notebooks) containing lines like this:\n",
    "- VARIABLE_NAME=value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "54790248-916b-4cc2-bc22-36cbdca4baf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cpu\n",
      "Token will not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n",
      "Token is valid (permission: write).\n",
      "Your token has been saved to /Users/christybergman/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "# Import torch.\n",
    "import torch\n",
    "from torch.nn import functional as F\n",
    "\n",
    "# Initialize torch settings\n",
    "torch.backends.cudnn.deterministic = True\n",
    "RANDOM_SEED = 415\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "DEVICE = torch.device('cuda:3' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"device: {DEVICE}\")\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "from huggingface_hub import login\n",
    "\n",
    "# Login to huggingface_hub\n",
    "hub_token = os.getenv(\"HUGGINGFACEHUB_API_TOKEN\")\n",
    "login(token=hub_token)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5e0cc471",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sentence_transformers.SentenceTransformer.SentenceTransformer'>\n",
      "SentenceTransformer(\n",
      "  (0): Transformer({'max_seq_length': 512, 'do_lower_case': True}) with Transformer model: BertModel \n",
      "  (1): Pooling({'word_embedding_dimension': 768, 'pooling_mode_cls_token': True, 'pooling_mode_mean_tokens': False, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False})\n",
      ")\n",
      "model_name: BAAI/bge-base-en-v1.5\n",
      "EMBEDDING_LENGTH: 768\n",
      "MAX_SEQ_LENGTH: 512\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Load the model from huggingface model hub.\n",
    "model_name = \"BAAI/bge-base-en-v1.5\"\n",
    "retriever = SentenceTransformer(model_name, device=DEVICE)\n",
    "print(type(retriever))\n",
    "print(retriever)\n",
    "\n",
    "# Get the model parameters and save for later.\n",
    "MAX_SEQ_LENGTH = retriever.get_max_seq_length() \n",
    "HF_EOS_TOKEN_LENGTH = 1\n",
    "EMBEDDING_LENGTH = retriever.get_sentence_embedding_dimension()\n",
    "\n",
    "# Inspect model parameters.\n",
    "print(f\"model_name: {model_name}\")\n",
    "print(f\"EMBEDDING_LENGTH: {EMBEDDING_LENGTH}\")\n",
    "print(f\"MAX_SEQ_LENGTH: {MAX_SEQ_LENGTH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a53595fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunk_size: 511, overlap: 51.0\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "chunk_size = MAX_SEQ_LENGTH - HF_TOKEN_EOS_LENGTH\n",
    "chunk_overlap = np.round(chunk_size * 0.10, 0)\n",
    "print(f\"chunk_size: {chunk_size}, overlap: {chunk_overlap}\")\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=chunk_size,\n",
    "    chunk_overlap=chunk_overlap,\n",
    "    length_function=len,\n",
    ")\n",
    "\n",
    "def chunk_text(text):\n",
    "    chunks = text_splitter.split_text(text)\n",
    "    return [chunk for chunk in chunks if chunk]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "249e9c74",
   "metadata": {},
   "source": [
    "**Only inserting 100 rows for demonstration purposes.**\n",
    "\n",
    "This means the query results likely will not be very good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0f915aed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_index</th>\n",
       "      <th>text</th>\n",
       "      <th>chunk</th>\n",
       "      <th>embeddings</th>\n",
       "      <th>label_int</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>26813</td>\n",
       "      <td>Fot the most part, this movie feels like a \"ma...</td>\n",
       "      <td>Fot the most part, this movie feels like a \"ma...</td>\n",
       "      <td>[-0.022307869, -0.038372956, -0.005369567, -0....</td>\n",
       "      <td>0</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>26813</td>\n",
       "      <td>Fot the most part, this movie feels like a \"ma...</td>\n",
       "      <td>more than some can handle just for that reason...</td>\n",
       "      <td>[0.02946616, -0.024044147, -0.011064137, -0.03...</td>\n",
       "      <td>0</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  movie_index                                               text  \\\n",
       "0       26813  Fot the most part, this movie feels like a \"ma...   \n",
       "1       26813  Fot the most part, this movie feels like a \"ma...   \n",
       "\n",
       "                                               chunk  \\\n",
       "0  Fot the most part, this movie feels like a \"ma...   \n",
       "1  more than some can handle just for that reason...   \n",
       "\n",
       "                                          embeddings  label_int     label  \n",
       "0  [-0.022307869, -0.038372956, -0.005369567, -0....          0  Negative  \n",
       "1  [0.02946616, -0.024044147, -0.011064137, -0.03...          0  Negative  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type embeddings: <class 'pandas.core.series.Series'> of <class 'numpy.ndarray'>\n",
      "of numbers: <class 'numpy.float32'>\n"
     ]
    }
   ],
   "source": [
    "# Prepare df for insertion into Milvus index.\n",
    "\n",
    "# Batch of data from pandas DataFrame.\n",
    "batch = df.head(100).copy()  \n",
    "\n",
    "# 1. Change primary key type to string.\n",
    "batch[\"movie_index\"] = batch[\"movie_index\"].apply(lambda x: str(x))\n",
    "\n",
    "# 2. Truncate reviews to 512 characters.\n",
    "# Naive approach, just truncate to 512 characters.\n",
    "# batch[\"text\"] = batch[\"text\"].apply(lambda x: x[:MAX_SEQ_LENGTH - HF_EOS_TOKEN_LENGTH])\n",
    "\n",
    "# Better approach, use LangChain's utility function that adds chunk overlaps.\n",
    "batch['chunk'] = batch['text'].apply(chunk_text)\n",
    "# Explode the 'chunk' column to create new rows for each chunk.\n",
    "batch = batch.explode('chunk', ignore_index=True)\n",
    "\n",
    "# 3. Add embeddings as new column in df.\n",
    "review_embeddings = torch.tensor(retriever.encode(batch['chunk']))\n",
    "# Normalize embeddings to unit length.\n",
    "review_embeddings = F.normalize(review_embeddings, p=2, dim=1)\n",
    "# Quick check if embeddings are normalized.\n",
    "norms = np.linalg.norm(review_embeddings, axis=1)\n",
    "assert np.allclose(norms, 1.0, atol=1e-5) == True\n",
    "\n",
    "# 4. Convert embeddings to list of `numpy.ndarray`, each containing `numpy.float32` numbers.\n",
    "converted_values = list(map(np.float32, review_embeddings))\n",
    "batch['embeddings'] = converted_values\n",
    "\n",
    "# 5. Reorder columns for conveneince, so index first, labels at end.\n",
    "new_order = [\"movie_index\", \"text\", \"chunk\", \"embeddings\", \"label_int\", \"label\"]\n",
    "batch = batch[new_order]\n",
    "\n",
    "# Inspect data.\n",
    "display(batch.head(2))\n",
    "assert len(batch.chunk[0]) <= MAX_SEQ_LENGTH-1\n",
    "assert len(batch.embeddings[0]) == EMBEDDING_LENGTH\n",
    "print(f\"type embeddings: {type(batch.embeddings)} of {type(batch.embeddings[0])}\")\n",
    "print(f\"of numbers: {type(batch.embeddings[0][0])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6233d309",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original\n",
      "56    Dr. K(David H Hickey)has been trying to master...\n",
      "Name: text, dtype: object\n",
      "chunked\n",
      "Dr. K(David H Hickey)has been trying to master a formula that would end all disease and handicaps, but needs live donors to complete his work. His doctor brother Richard(Dennis O'Neill)has a son named Eddie(Derek Philips)who is accepted to medical school. Eddie has a girlfriend named Sarah(Lizabeth Cardenas)who is pre-law and plans to attend law school herself the coming fall. She and Eddie resume their relationship when Sarah calls things off with her current boyfriend who is also shagging the lady of\n",
      "current boyfriend who is also shagging the lady of Walt(Bill Sebastian;Eddie's best friend who recently paid for his cheating girlfriend's boob job). Eddie accidentally gets hit by a car and appears on the throes of death when Dr. K makes a suggestion to Richard..let him \"recuperate\" Eddie using his secret, illegal methods. When Dr. K applies his serum to Eddie horrifying results occur. Eddie's face bulges massive warts while he has also acquired a taste for human flesh. Many will die so that Eddie can\n",
      "for human flesh. Many will die so that Eddie can feed this uncontrollable appetite he can't quench. Soon he may even pose a threat to his father and girlfriend..Eddie Monster must be stopped.<br /><br />Typically awful direct-to-video horror flick suffers from a severe lack of budget, acting, and overall talent. The premise, which seems like an interesting fright-fest, fails to deliver even as a zombie flick. The gore is limited with a few munching scenes but most of the violence occurs off-camera. The\n",
      "but most of the violence occurs off-camera. The use of time to move the story along can really get annoying.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_index</th>\n",
       "      <th>chunk</th>\n",
       "      <th>embeddings</th>\n",
       "      <th>label_int</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>26813</td>\n",
       "      <td>Fot the most part, this movie feels like a \"ma...</td>\n",
       "      <td>[-0.022307869, -0.038372956, -0.005369567, -0....</td>\n",
       "      <td>0</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>26813</td>\n",
       "      <td>more than some can handle just for that reason...</td>\n",
       "      <td>[0.02946616, -0.024044147, -0.011064137, -0.03...</td>\n",
       "      <td>0</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  movie_index                                              chunk  \\\n",
       "0       26813  Fot the most part, this movie feels like a \"ma...   \n",
       "1       26813  more than some can handle just for that reason...   \n",
       "\n",
       "                                          embeddings  label_int     label  \n",
       "0  [-0.022307869, -0.038372956, -0.005369567, -0....          0  Negative  \n",
       "1  [0.02946616, -0.024044147, -0.011064137, -0.03...          0  Negative  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect chunking of the data.\n",
    "print(\"original\")\n",
    "print(df.loc[(df.movie_index==931), \"text\"])\n",
    "print(\"chunked\")\n",
    "checkit = list(batch.loc[(batch.movie_index==\"931\"), \"chunk\"])\n",
    "[print(chunk) for chunk in checkit]\n",
    "\n",
    "# Chunking looks good, drop the original text column.\n",
    "batch.drop(columns=[\"text\"], inplace=True)\n",
    "batch.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9bd8153",
   "metadata": {},
   "source": [
    "## Insert data into Milvus\n",
    "\n",
    "We can insert data directly from a pandas dataframe into Milvus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b51ff139",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start inserting entities\n",
      "(insert count: 290, delete count: 0, upsert count: 0, timestamp: 444683530472783875, success count: 290, err count: 0)\n",
      "[{\"name\":\"_default\",\"collection_name\":\"movies\",\"description\":\"\"}]\n"
     ]
    }
   ],
   "source": [
    "# Insert data into the Milvus collection.\n",
    "print(\"Start inserting entities\")\n",
    "insert_result = mc.insert(batch)\n",
    "\n",
    "# After final entity is inserted, call flush to stop growing segments left in memory.\n",
    "mc.flush() \n",
    "\n",
    "# Inspect results.\n",
    "print(insert_result)\n",
    "print(mc.partitions) # list[Partition] objects"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ebfb115",
   "metadata": {},
   "source": [
    "## Run a Semantic Search\n",
    "\n",
    "Now we can search all the movie review embeddings to find the `TOP_K` movie reviews with the closest embeddings to a user's question.\n",
    "- In this example, we'll search for a movie recommendation for a medical doctor.\n",
    "\n",
    "Note:  The same model should always be used for consistency for all the embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eb7bc132",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded milvus collection into memory.\n"
     ]
    }
   ],
   "source": [
    "# Before conducting a search or a query, you need to load the data into memory.\n",
    "mc.load()\n",
    "print(\"Loaded milvus collection into memory.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02c589ff",
   "metadata": {},
   "source": [
    "**Ask a question about your data**\n",
    "\n",
    "Your custom data is mapped into a vector embedding space and those vector embeddings are saved into a vector database.  \n",
    "\n",
    "Next, you can ask a question about your custom data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5e7f41f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query length: 48\n"
     ]
    }
   ],
   "source": [
    "# Define a sample question about your data.\n",
    "query = \"I'm a medical doctor, what movie should I watch?\"\n",
    "\n",
    "# Inspect the length of the query.\n",
    "QUERY_LENGTH = len(query)\n",
    "print(f\"query length: {QUERY_LENGTH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa545611",
   "metadata": {},
   "source": [
    "**Embed the query using the same embedding model you used earlier**\n",
    "\n",
    "In order for vector search to work, the query itself should be embedded with the same model used to create the colleciton you want to search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a6863a32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'> 1 <class 'numpy.ndarray'>\n",
      "<class 'numpy.float32'>\n"
     ]
    }
   ],
   "source": [
    "# Embed the query using same embedding model used to create the Milvus collection.\n",
    "query_embeddings = torch.tensor(retriever.encode([query]))\n",
    "# Normalize embeddings to unit length.\n",
    "query_embeddings = torch.nn.functional.normalize(query_embeddings, p=2, dim=1)\n",
    "# Quick check if embeddings are normalized.\n",
    "norms = np.linalg.norm(query_embeddings, axis=1)\n",
    "assert np.allclose(norms, 1.0, atol=1e-5) == True\n",
    "\n",
    "# Convert the embeddings to list of list of np.float32.\n",
    "query_embeddings = list(map(np.float32, query_embeddings))\n",
    "\n",
    "# Inspect data.\n",
    "print(type(query_embeddings), len(query_embeddings), type(query_embeddings[0]))\n",
    "print(type(query_embeddings[0][0]) ) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ea29411",
   "metadata": {},
   "source": [
    "## Execute a vector search\n",
    "\n",
    "Query Milvus using [PyMilvus API](https://milvus.io/docs/search.md)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c5d98e28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.008866071701049805\n",
      "type: <class 'pymilvus.orm.search.SearchResult'>, count: 3\n"
     ]
    }
   ],
   "source": [
    "# Execute a search.\n",
    "\n",
    "# Return top k results with HNSW index.\n",
    "TOP_K = 3\n",
    "search_params = {\n",
    "    \"M\": 16,\n",
    "    \"ef\": 32,\n",
    "}\n",
    "\n",
    "start_time = time.time()\n",
    "results = mc.search(\n",
    "    data=query_embeddings, \n",
    "    anns_field=\"embeddings\", \n",
    "    param=search_params,\n",
    "    output_fields=[\"movie_index\", \"chunk\", \"label\"], \n",
    "    limit=TOP_K,\n",
    "    consistency_level=\"Eventually\"\n",
    "    )\n",
    "\n",
    "elapsed_time = time.time() - start_time\n",
    "print(elapsed_time)\n",
    "\n",
    "print(f\"type: {type(results)}, count: {len(results[0])}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95f7e011",
   "metadata": {},
   "source": [
    "## Assemble and inspect the query result\n",
    "\n",
    "The query result is in the variable `result[0]` of type `'pymilvus.orm.search.SearchResult'`.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d3dfa33a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the distances to the query vector from all returned hits\n",
    "distances = results[0].distances\n",
    "\n",
    "# Get the movie_indexes, review texts, and labels.\n",
    "texts = []\n",
    "movie_indexes = []\n",
    "labels = []\n",
    "for result in results[0]:\n",
    "    texts.append(result.entity.get(\"chunk\"))\n",
    "    movie_indexes.append(result.entity.get(\"movie_index\"))\n",
    "    # movie_indexes.append(0)\n",
    "    labels.append(result.entity.get(\"label\"))\n",
    "    # labels.append(\"Positive\")\n",
    "\n",
    "# Assemble all the results in a zipped list.\n",
    "print_info = list(zip(distances, movie_indexes, texts, labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "22d65363",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: 0.541, 931, Negative, Dr. K(David H Hickey)has been trying to master a formula that would end all disease and handicaps, b\n",
      "1: 0.54, 20682, Positive, is not a horror movie, although it does contain some violent scenes, but is rather a comedy. A satir\n",
      "2: 0.535, 12529, Positive, a good movie with a real good story. The fact that there are so many other big stars who all also ha\n"
     ]
    }
   ],
   "source": [
    "# Print the results.\n",
    "# k: distance, movie_index, label, review text\n",
    "\n",
    "i = 0\n",
    "for row in print_info:\n",
    "    # print(row)\n",
    "    print(f\"{i}: {np.round(row[0],3)}, {row[1]}, {row[3]}, {row[2][:100]}\")\n",
    "    i += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "822239ba",
   "metadata": {},
   "source": [
    "**Repeat the same thing using LangChain APIs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fa5a0737",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts.example_selector import (\n",
    "    MaxMarginalRelevanceExampleSelector,\n",
    "    SemanticSimilarityExampleSelector,\n",
    ")\n",
    "from langchain.vectorstores import Milvus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd7205b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d0e81e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shut down and cleanup the milvus server.\n",
    "default_server.stop()\n",
    "default_server.cleanup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c777937e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Author: Christy Bergman\n",
      "\n",
      "Python implementation: CPython\n",
      "Python version       : 3.10.12\n",
      "IPython version      : 8.15.0\n",
      "\n",
      "torch       : 2.0.1\n",
      "transformers: 4.33.2\n",
      "milvus      : 2.3.0\n",
      "pymilvus    : 2.3.0\n",
      "langchain   : 0.0.301\n",
      "\n",
      "conda environment: py310\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%load_ext watermark\n",
    "%watermark -a 'Christy Bergman' -v -p torch,transformers,milvus,pymilvus,langchain --conda"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
